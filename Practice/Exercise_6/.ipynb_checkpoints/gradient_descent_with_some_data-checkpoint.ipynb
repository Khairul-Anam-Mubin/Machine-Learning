{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe3d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ceb044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>math</th>\n",
       "      <th>cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>david</td>\n",
       "      <td>92</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>laura</td>\n",
       "      <td>56</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sanjay</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wei</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jeff</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aamir</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>venkat</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>virat</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>arthur</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paul</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  math  cs\n",
       "0   david    92  98\n",
       "1   laura    56  68\n",
       "2  sanjay    88  81\n",
       "3     wei    70  80\n",
       "4    jeff    80  83\n",
       "5   aamir    49  52\n",
       "6  venkat    65  66\n",
       "7   virat    35  30\n",
       "8  arthur    66  68\n",
       "9    paul    67  73"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test_scores.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bfb06f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([92, 56, 88, 70, 80, 49, 65, 35, 66, 67], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(df['math'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5275d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98, 68, 81, 80, 83, 52, 66, 30, 68, 73], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(df['cs'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c95ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mean_Square_Error(y , y_predicted):\n",
    "    sum = 0\n",
    "    n = len(y)\n",
    "    for i in range(n):\n",
    "        sum += ((y[i] - y_predicted[i]) ** 2)\n",
    "    cost = (1 / n) * sum\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "891ad85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Descent(x , y):\n",
    "    m_cur = b_cur = 0\n",
    "    iterations = 100\n",
    "    n = len(x)\n",
    "    learning_rate = 0.0002\n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_cur * x + b_cur #as x is numpy m_cur * x will multiply all the elements in x\n",
    "        cost = Mean_Square_Error(y , y_predicted)\n",
    "        m_derivative = -(2 /n) * sum(x * (y - y_predicted))\n",
    "        b_derivative = -(2 /n) * sum(y - y_predicted)\n",
    "        m_cur = m_cur - learning_rate * m_derivative\n",
    "        b_cur = b_cur - learning_rate * b_derivative\n",
    "        print(\"iter = \", i + 1, \"m = \", m_cur, \" b = \", b_cur, \" loss = \" , cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aaf56ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter =  1 m =  1.9783600000000003  b =  0.027960000000000002  loss =  5199.1\n",
      "iter =  2 m =  0.20975041279999962  b =  0.0030470367999999894  loss =  4161.482445460163\n",
      "iter =  3 m =  1.7908456142986242  b =  0.025401286955264  loss =  3332.2237319269248\n",
      "iter =  4 m =  0.37738163667530467  b =  0.005499731626422651  loss =  2669.4843523161976\n",
      "iter =  5 m =  1.6409848166378898  b =  0.023373894401807944  loss =  2139.826383775145\n",
      "iter =  6 m =  0.5113514173939655  b =  0.0074774305434828076  loss =  1716.5264071567592\n",
      "iter =  7 m =  1.5212165764726306  b =  0.021771129698498662  loss =  1378.2272007804495\n",
      "iter =  8 m =  0.6184191426785134  b =  0.009075514323270572  loss =  1107.8601808918404\n",
      "iter =  9 m =  1.4254981563597626  b =  0.020507724625171385  loss =  891.7842215178443\n",
      "iter =  10 m =  0.7039868810749315  b =  0.010370210797388455  loss =  719.0974036421305\n",
      "iter =  11 m =  1.3490002310389348  b =  0.01951553325074733  loss =  581.0869686205\n",
      "iter =  12 m =  0.7723719384951477  b =  0.01142244086408669  loss =  470.7897237271261\n",
      "iter =  13 m =  1.2878632281408475  b =  0.018740093691150705  loss =  382.6407204862143\n",
      "iter =  14 m =  0.8270246840299113  b =  0.012280892197750798  loss =  312.1924801681589\n",
      "iter =  15 m =  1.2390025969113474  b =  0.01813788028359247  loss =  255.89060022344475\n",
      "iter =  16 m =  0.8707026352388424  b =  0.012984475742007832  loss =  210.89442007737276\n",
      "iter =  17 m =  1.1999531799587442  b =  0.01767410753812916  loss =  174.93369813849728\n",
      "iter =  18 m =  0.9056095862354473  b =  0.013564288926616264  loss =  146.19406878727372\n",
      "iter =  19 m =  1.168744835939885  b =  0.017320975066834464  loss =  123.2255001796068\n",
      "iter =  20 m =  0.9335067981503328  b =  0.014045184660493999  loss =  104.86913418555842\n",
      "iter =  21 m =  1.1438030378387343  b =  0.017056264940052912  loss =  90.1988172376793\n",
      "iter =  22 m =  0.9558018619881088  b =  0.014447025263025912  loss =  78.4743720801518\n",
      "iter =  23 m =  1.123869431612398  b =  0.016862220700598438  loss =  69.10425278659366\n",
      "iter =  24 m =  0.9736197173740411  b =  0.014785684599634922  loss =  61.61569883880534\n",
      "iter =  25 m =  1.1079383470620547  b =  0.016724651477560692  loss =  55.63088241716976\n",
      "iter =  26 m =  0.9878594103778675  b =  0.015073848983471565  loss =  50.84784543555072\n",
      "iter =  27 m =  1.0952060576414993  b =  0.016632215998581557  loss =  47.02526451581355\n",
      "iter =  28 m =  0.9992394540800741  b =  0.015321657252001263  loss =  43.970275232370476\n",
      "iter =  29 m =  1.0850302291522722  b =  0.01657585037608088  loss =  41.528741309884765\n",
      "iter =  30 m =  1.0083340805074807  b =  0.015537212312981736  loss =  39.57747781519814\n",
      "iter =  31 m =  1.0768975113455124  b =  0.01654831079689666  loss =  38.01803597157669\n",
      "iter =  32 m =  1.0156022129971571  b =  0.01572698996942581  loss =  36.77173601363096\n",
      "iter =  33 m =  1.0703976372937574  b =  0.016543808042154003  loss =  35.775697470042715\n",
      "iter =  34 m =  1.0214106207634122  b =  0.015896165650447946  loss =  34.97966658555935\n",
      "iter =  35 m =  1.0652027237396349  b =  0.016557715397389393  loss =  34.34348081266759\n",
      "iter =  36 m =  1.0260524239108442  b =  0.016048875532907396  loss =  33.83504244613808\n",
      "iter =  37 m =  1.0610507280390304  b =  0.01658633521579648  loss =  33.42869916198312\n",
      "iter =  38 m =  1.0297618825473565  b =  0.016188425228507268  loss =  33.103949752366304\n",
      "iter =  39 m =  1.0577322270335765  b =  0.0166267123567505  loss =  32.84440975547639\n",
      "iter =  40 m =  1.0327262161686235  b =  0.016317456565470633  loss =  32.636984792143764\n",
      "iter =  41 m =  1.0550798507922887  b =  0.016676485086818824  loss =  32.47120990063734\n",
      "iter =  42 m =  1.035095049650491  b =  0.016438080879614143  loss =  32.33872153636954\n",
      "iter =  43 m =  1.052959838111218  b =  0.01673376592060118  loss =  32.23283559672576\n",
      "iter =  44 m =  1.036987962438417  b =  0.016551985539901195  loss =  32.14821018063812\n",
      "iter =  45 m =  1.0512652877114044  b =  0.01679704638933073  loss =  32.08057606773955\n",
      "iter =  46 m =  1.0385005218215662  b =  0.016660519083126275  loss =  32.02652131866401\n",
      "iter =  47 m =  1.0499107646303472  b =  0.016865120932420777  loss =  31.983319128693804\n",
      "iter =  48 m =  1.0397091046950075  b =  0.01676475925312493  loss =  31.94879024926364\n",
      "iter =  49 m =  1.0488279896772978  b =  0.01693702607197308  loss =  31.921193035921274\n",
      "iter =  50 m =  1.0406747510877237  b =  0.016865567377366896  loss =  31.899135575212195\n",
      "iter =  51 m =  1.047962394467687  b =  0.017011991801351975  loss =  31.881505456930224\n",
      "iter =  52 m =  1.0414462438827428  b =  0.016963631824454838  loss =  31.86741364845402\n",
      "iter =  53 m =  1.0472703682240316  b =  0.01708940273517817  loss =  31.85614963940047\n",
      "iter =  54 m =  1.0420625701139212  b =  0.017059502735137972  loss =  31.847145593458148\n",
      "iter =  55 m =  1.046717057433117  b =  0.017168767060599943  loss =  31.839947698713402\n",
      "iter =  56 m =  1.0425548880219075  b =  0.017153619779162816  loss =  31.83419327097573\n",
      "iter =  57 m =  1.0462746073431242  b =  0.01724969172330578  loss =  31.829592454870966\n",
      "iter =  58 m =  1.0429480991153375  b =  0.017246334338408182  loss =  31.825913599447194\n",
      "iter =  59 m =  1.0459207565770121  b =  0.017331862596311  loss =  31.82297157043309\n",
      "iter =  60 m =  1.0432621045542085  b =  0.017337927235534713  loss =  31.82061840945363\n",
      "iter =  61 m =  1.0456377139546258  b =  0.017415028630952047  loss =  31.81873586892226\n",
      "iter =  62 m =  1.0435128092451273  b =  0.017428622902632068  loss =  31.81722944596486\n",
      "iter =  63 m =  1.0454112608545958  b =  0.01749898919044121  loss =  31.816023614361388\n",
      "iter =  64 m =  1.0437129243091645  b =  0.017518600704730235  loss =  31.81505801393808\n",
      "iter =  65 m =  1.0452300338265001  b =  0.017583583926907467  loss =  31.81428440514876\n",
      "iter =  66 m =  1.0438726084101126  b =  0.01760800398949262  loss =  31.81366423519171\n",
      "iter =  67 m =  1.0450849512581242  b =  0.017668684691178615  loss =  31.813166692862268\n",
      "iter =  68 m =  1.043999980300792  b =  0.017696947319685068  loss =  31.812767154001268\n",
      "iter =  69 m =  1.0449687551708302  b =  0.017754189067120032  loss =  31.812445939105075\n",
      "iter =  70 m =  1.0441015284474728  b =  0.017785522253328603  loss =  31.81218732041362\n",
      "iter =  71 m =  1.0448756450247292  b =  0.017840015204310798  loss =  31.811978728380467\n",
      "iter =  72 m =  1.0441824383996428  b =  0.01787380196316831  loss =  31.81181011748764\n",
      "iter =  73 m =  1.0448009850576234  b =  0.01792609768834459  loss =  31.811673459407757\n",
      "iter =  74 m =  1.0442468544222752  b =  0.017961844928529556  loss =  31.811562337942128\n",
      "iter =  75 m =  1.0447410703917646  b =  0.01801238424039495  loss =  31.811471625297237\n",
      "iter =  76 m =  1.0442980885910158  b =  0.018049697885830843  loss =  31.811397223366267\n",
      "iter =  77 m =  1.044692940107559  b =  0.01809883307952457  loss =  31.811335856963026\n",
      "iter =  78 m =  1.0443387879000003  b =  0.018137398186618782  loss =  31.811284908575193\n",
      "iter =  79 m =  1.044654227853013  b =  0.018185410814656123  loss =  31.811242286300104\n",
      "iter =  80 m =  1.04437106781358  b =  0.01822497568209775  loss =  31.811206318299767\n",
      "iter =  81 m =  1.044623042451559  b =  0.018272090759846052  loss =  31.811175668449643\n",
      "iter =  82 m =  1.0443966190001837  b =  0.018312454229236455  loss =  31.81114926892579\n",
      "iter =  83 m =  1.044597872484431  b =  0.018358851587859853  loss =  31.81112626632863\n",
      "iter =  84 m =  1.0444167926334849  b =  0.018399852894440714  loss =  31.811105978625633\n",
      "iter =  85 m =  1.0445775100333783  b =  0.018445676254116222  loss =  31.811087860739732\n",
      "iter =  86 m =  1.0444326685646632  b =  0.01848718691552271  loss =  31.81107147704813\n",
      "iter =  87 m =  1.0445609897362342  b =  0.0185325511367087  loss =  31.81105647940329\n",
      "iter =  88 m =  1.044445109805328  b =  0.018574468470501836  loss =  31.81104258956744\n",
      "iter =  89 m =  1.044547540080427  b =  0.01861946534911527  loss =  31.811029585174346\n",
      "iter =  90 m =  1.044454806070002  b =  0.018661707292026614  loss =  31.81101728851003\n",
      "iter =  91 m =  1.0445365444770032  b =  0.01870641019091935  loss =  31.81100555754639\n",
      "iter =  92 m =  1.0444623085750486  b =  0.01874891115841746  loss =  31.810994278775315\n",
      "iter =  93 m =  1.0445275101511837  b =  0.018793378708828794  loss =  31.810983361481625\n",
      "iter =  94 m =  1.0444680578498022  b =  0.01883608628610563  loss =  31.810972733166256\n",
      "iter =  95 m =  1.044520043279852  b =  0.018880365345844474  loss =  31.810962335888206\n",
      "iter =  96 m =  1.0444724059630832  b =  0.01892323764326849  loss =  31.810952123341476\n",
      "iter =  97 m =  1.0445138291215608  b =  0.0189673656608776  loss =  31.810942058518464\n",
      "iter =  98 m =  1.0444756342865145  b =  0.01901036920048514  loss =  31.810932111842874\n",
      "iter =  99 m =  1.0445086161365338  b =  0.01905437610466928  loss =  31.81092225967744\n",
      "iter =  100 m =  1.0444779676908766  b =  0.01909748413105923  loss =  31.81091248313143\n"
     ]
    }
   ],
   "source": [
    "Gradient_Descent(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539d4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58d4b7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LinearRegression()\n",
    "model.fit([x] , [y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92e45f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd8a7f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98., 68., 81., 80., 83., 52., 66., 30., 68., 73.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
